{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess_raw import *\n",
    "from preprocess_transformed import *\n",
    "from model_setup_fit import *\n",
    "from model_optimization import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.get_option(\"display.max_rows\",999)\n",
    "pd.get_option(\"display.max_columns\",999)\n",
    "pd.get_option(\"display.width\",None)\n",
    "\n",
    "GITHUB = os.environ.get(\"GITHUB\")\n",
    "sys.path.insert(0, GITHUB + 'Machine_Cleaning_2019/modeling/src')\n",
    "\n",
    "HOST_FORKED = os.environ.get(\"HOST_FORKED\")\n",
    "USER_FORKED = os.environ.get(\"USER_FORKED\")\n",
    "PASSWORD_FORKED = os.environ.get(\"PASSWORD_FORKED\")\n",
    "DB_FORKED = os.environ.get(\"DB_FORKED\")\n",
    "\n",
    "HOST_DAR = os.environ.get(\"HOST_DAR\")\n",
    "USER_DAR = os.environ.get(\"USER_DAR\")\n",
    "PASSWORD_DAR = os.environ.get(\"PASSWORD_DAR\")\n",
    "DB_DAR = os.environ.get(\"DB_DAR\")\n",
    "   \n",
    "## Function to load in a model and features and apply it to new data. \n",
    "    # Outputs a data frame with 2 columns: line_item_id (pristine table), predicted variable\n",
    "    # Must input the data frame to predict on (after the minimal preprocessing) and a model id (string)    \n",
    "def load_and_predict(data, model_id):\n",
    "    list_unpickle = open('objects/feature_cols/features_' + model_id + '.pkl', 'r')\n",
    "    # load the unpickle object into a variable\n",
    "    model_cols = load(list_unpickle)\n",
    "    print len(model_cols)\n",
    "\n",
    "    # make data frame from dm.ml_model_results_lookup for the model\n",
    "    model_results_lookup = get_table_from_db(\"select * from dm.ml_model_results_lookup where model_id = '\" + model_id + \"';\", 'string', \n",
    "                                              HOST_FORKED, USER_FORKED, PASSWORD_FORKED, DB_FORKED)\n",
    "    yvar = model_results_lookup['y'].item() \n",
    "        \n",
    "    # load model\n",
    "    model = load(open('objects/models/model_' + model_id + '.pkl', 'rb'))\n",
    "    print model\n",
    "    # create imputer (based on output table)\n",
    "    imputer = Imputer(strategy=model_results_lookup['imputer'].item())\n",
    "\n",
    "    # subset to particular model's columns\n",
    "    data_model = data[model_cols]\n",
    "    print data_model.shape\n",
    "    # impute missing values\n",
    "    data_model = imputer.fit_transform(data_model)\n",
    "    # predict\n",
    "    y_pred = model.predict(data_model) \n",
    "    # need to add predict_proba()\n",
    "    y_pred_proba = model.predict_proba(data_model)\n",
    "    df_pred_probab = pd.DataFrame(y_pred_proba).reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    # Get label encoder for y variable (for classification)\n",
    "    if yvar != 'fiber_binary' and yvar != 'num_lines' and yvar != 'exclude':\n",
    "        yquery = get_clean_y_query(yvar,'get_yvar_dar_prod.sql')\n",
    "        \n",
    "        yclean = get_table_from_db(yquery, 'string', HOST_DAR, USER_DAR, PASSWORD_DAR, DB_DAR)\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        \n",
    "        if yvar == 'connect_category':\n",
    "            labels = np.append(yclean[yvar],'Uncategorized')\n",
    "            le.fit(labels)\n",
    "        else:\n",
    "            le.fit(yclean[yvar])\n",
    "\n",
    "        # get pretty names\n",
    "        y_pred = le.inverse_transform(y_pred)\n",
    "\n",
    "    # concatenate\n",
    "    line_item_id = pd.Series(data['frn_adjusted']).reset_index(drop=True) ## WILL BE DIFFERENT\n",
    "    y_pred = pd.Series(y_pred).reset_index(drop=True)\n",
    "    output = pd.concat([line_item_id, y_pred, df_pred_probab],axis=1)\n",
    "    output.columns = ['line_item_id','prediction'] + le.classes_.tolist()\n",
    "    \n",
    "    # print category diffs\n",
    "    if yvar != 'fiber_binary' and yvar != 'num_lines' and yvar != 'exclude':\n",
    "        y_counts = yclean[yvar].value_counts(normalize=True).reset_index()\n",
    "        ypred_counts = output.prediction.value_counts(normalize=True).reset_index()\n",
    "        compdf = y_counts.merge(ypred_counts,on='index')\n",
    "        compdf['absdiff'] = abs(compdf[yvar] - compdf['prediction'])\n",
    "        print \"y-variable distributions comparison:\"\n",
    "        print compdf\n",
    "    else:\n",
    "        print output.prediction.value_counts()\n",
    "        \n",
    "    return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying data from DB connection\n",
      "Trying to establish initial connection to the server\n",
      "Success!\n",
      "Finished querying data\n"
     ]
    }
   ],
   "source": [
    "# replace with get_data_future_predict.sql!!! also, credentials will probably be different\n",
    "raw_data_predict = get_table_from_db('get_data_2019_train.sql', 'file', \n",
    "                                     HOST=HOST_FORKED,\n",
    "                                     USER=USER_FORKED,\n",
    "                                     PASSWORD=PASSWORD_FORKED, \n",
    "                                     DB=DB_FORKED\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47165, 118)\n",
      "['account_number', 'actual_start_date', 'annual_interest_rate', 'appeal_wave_number', 'application_number', 'average_cost_per_foot_of_outside_plant', 'award_date', 'baloon_payment', 'based_on_multiple_award_schedule', 'based_on_state_master_contract', 'basic_firewall_protection', 'ben', 'billed_entity_name', 'billed_entity_type', 'burstable_speed', 'burstable_speed_units', 'connected_directly_to_school_library_or_nif', 'connection_supports_school_library_or_nif', 'connection_used_by', 'contact_email', 'contract_end_time', 'contract_expiration_date', 'contract_number', 'contract_type', 'created_at', 'discount_rate', 'download_speed', 'download_speed_mbps', 'download_speed_units', 'establishing_fcc_form470', 'extended_contract_expiration_date', 'fcc_form486', 'fcc_form486_case_status', 'fcc_form486_invoicing_ready', 'fcdl_comment_app', 'fcdl_comment_frn', 'fcdl_letter_date', 'fiber_sub_type', 'fiber_type', 'form_version', 'frn', 'frn_adjusted', 'frn_number_from_the_previous_year', 'frn_previous_year_exists', 'frn_status', 'function', 'funding_commitment_request', 'funding_request_nickname', 'funding_year', 'id', 'includes_voluntary_extensions', 'invoicing_mode', 'is_installation_included_in_price', 'is_lease', 'last_date_to_invoice', 'lease_or_non_purchase_agreement', 'line_item', 'make', 'match_amount', 'model', 'monthly_quantity', 'monthly_recurring_unit_costs', 'monthly_recurring_unit_eligible_costs', 'monthly_recurring_unit_ineligible_costs', 'months_of_service', 'narrative', 'num_bids_received', 'number_of_erate_eligible_strands', 'old_form470_number', 'one_time_eligible_unit_costs', 'one_time_ineligible_unit_costs', 'one_time_quantity', 'one_time_unit_costs', 'other_manufacture', 'pending_reason', 'postal_cd', 'pre_discount_extended_eligible_line_item_cost', 'pricing_confidentiality', 'pricing_confidentiality_type', 'purpose', 'purpose_adj', 'remaining_voluntary_extensions', 'restriction_citation', 'revised_fcdl_date', 'service_provider_name', 'service_provider_number', 'service_start_date', 'service_type', 'source_of_matching_funds', 'special_construction_state_tribal_match_percentage', 'total_amount_financed', 'total_authorized_disbursement', 'total_eligible_one_time_costs', 'total_eligible_pre_discount_one_time_charges', 'total_eligible_pre_discount_recurring_charges', 'total_eligible_recurring_costs', 'total_ineligible_one_time_charges', 'total_monthly_eligible_charges', 'total_monthly_eligible_recurring_costs', 'total_monthly_ineligible_charges', 'total_monthly_recurring_charges', 'total_number_of_months_of_service', 'total_number_of_terms_in_months', 'total_one_time_charges', 'total_pre_discount_charges', 'total_project_plant_route_feet', 'total_remaining_contract_length', 'total_strands', 'type_of_product', 'unit', 'updated_at', 'upload_speed', 'upload_speed_mbps', 'upload_speed_units', 'user_generated_fcdl_date', 'was_fcc_form470_posted', 'wave_sequence_number', 'window_status']\n"
     ]
    }
   ],
   "source": [
    "print(raw_data_predict.shape)\n",
    "print(raw_data_predict.columns.sort_values().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** STARTING PRE-PROCESSING FOR RAW DATA ***\n",
      "Dropped 0 duplicate rows\n",
      "Dropped null columns: \n",
      "['actual_start_date', 'fiber_type', 'fiber_sub_type', 'total_project_plant_route_feet', 'average_cost_per_foot_of_outside_plant', 'total_strands', 'number_of_erate_eligible_strands', 'match_amount', 'source_of_matching_funds', 'total_amount_financed', 'total_number_of_terms_in_months', 'annual_interest_rate', 'baloon_payment', 'special_construction_state_tribal_match_percentage', 'pending_reason', 'fcc_form486', 'fcc_form486_case_status', 'fcc_form486_invoicing_ready', 'last_date_to_invoice', 'wave_sequence_number', 'fcdl_letter_date', 'user_generated_fcdl_date', 'fcdl_comment_app', 'fcdl_comment_frn', 'appeal_wave_number', 'revised_fcdl_date', 'invoicing_mode', 'total_authorized_disbursement', 'connection_used_by', 'make', 'model', 'other_manufacture', 'unit']\n",
      "months_of_service duplicate with total_number_of_months_of_service, dropping months_of_service\n",
      "lease_or_non_purchase_agreement duplicate with is_installation_included_in_price, dropping lease_or_non_purchase_agreement\n",
      "Dropped duplicate columns: \n",
      "['months_of_service', 'lease_or_non_purchase_agreement']\n",
      "Dropped: id\n",
      "Dropped: frn\n",
      "Dropped: frn_number_from_the_previous_year\n",
      "Dropped: application_number\n",
      "Dropped: ben\n",
      "Dropped: account_number\n",
      "Dropped: service_provider_number\n",
      "Dropped: establishing_fcc_form470\n",
      "Dropped: user_entered_establishing_fcc_form470\n",
      "Dropped: line_item\n",
      "Dropped: award_date\n",
      "Dropped: expiration_date\n",
      "Dropped: contract_expiration_date\n",
      "Dropped: service_start_date\n",
      "Dropped: model\n",
      "Dropped: contract_number\n",
      "Dropped: restriction_citation\n",
      "Dropped: other_manufacture\n",
      "Dropped: download_speed\n",
      "Dropped: download_speed_units\n",
      "Dropped: upload_speed\n",
      "Dropped: upload_speed_units\n",
      "Dropped: burstable_speed\n",
      "Dropped: burstable_speed_units\n",
      "Dropped: purpose\n",
      "Dropped: billed_entity_name\n",
      "Dropped: type_of_product\n",
      "Dropped: updated_at\n",
      "Dropped: created_at\n",
      "Dropped: extended_contract_expiration_date\n",
      "Dropped: window_status\n",
      "Renamed purpose_adj to purpose\n",
      "funding_year converted to float\n",
      "form_version float conversion failed\n",
      "contact_email float conversion failed\n",
      "frn_status float conversion failed\n",
      "funding_request_nickname float conversion failed\n",
      "service_type float conversion failed\n",
      "old_form470_number converted to float\n",
      "was_fcc_form470_posted float conversion failed\n",
      "service_provider_name float conversion failed\n",
      "includes_voluntary_extensions float conversion failed\n",
      "remaining_voluntary_extensions converted to float\n",
      "total_remaining_contract_length converted to float\n",
      "pricing_confidentiality float conversion failed\n",
      "narrative float conversion failed\n",
      "total_monthly_recurring_charges converted to float\n",
      "total_monthly_ineligible_charges converted to float\n",
      "total_monthly_eligible_charges converted to float\n",
      "total_number_of_months_of_service converted to float\n",
      "total_eligible_pre_discount_recurring_charges converted to float\n",
      "total_one_time_charges converted to float\n",
      "total_ineligible_one_time_charges converted to float\n",
      "total_eligible_pre_discount_one_time_charges converted to float\n",
      "total_pre_discount_charges converted to float\n",
      "discount_rate converted to float\n",
      "funding_commitment_request converted to float\n",
      "num_bids_received converted to float\n",
      "based_on_state_master_contract float conversion failed\n",
      "based_on_multiple_award_schedule float conversion failed\n",
      "is_lease float conversion failed\n",
      "basic_firewall_protection float conversion failed\n",
      "connected_directly_to_school_library_or_nif float conversion failed\n",
      "connection_supports_school_library_or_nif float conversion failed\n",
      "is_installation_included_in_price float conversion failed\n",
      "monthly_quantity converted to float\n",
      "monthly_recurring_unit_costs converted to float\n",
      "monthly_recurring_unit_eligible_costs converted to float\n",
      "monthly_recurring_unit_ineligible_costs converted to float\n",
      "one_time_eligible_unit_costs converted to float\n",
      "one_time_ineligible_unit_costs converted to float\n",
      "one_time_quantity converted to float\n",
      "one_time_unit_costs converted to float\n",
      "pre_discount_extended_eligible_line_item_cost converted to float\n",
      "total_eligible_one_time_costs converted to float\n",
      "total_eligible_recurring_costs converted to float\n",
      "total_monthly_eligible_recurring_costs converted to float\n",
      "frn_adjusted float conversion failed\n",
      "upload_speed_mbps converted to float\n",
      "download_speed_mbps converted to float\n",
      "contract_end_time converted to float\n",
      "frn_previous_year_exists float conversion failed\n",
      "connection_supports_school_library_or_nif converted to float\n",
      "includes_voluntary_extensions converted to float\n",
      "basic_firewall_protection converted to float\n",
      "based_on_state_master_contract converted to float\n",
      "based_on_multiple_award_schedule converted to float\n",
      "pricing_confidentiality converted to float\n",
      "connected_directly_to_school_library_or_nif converted to float\n",
      "was_fcc_form470_posted converted to float\n",
      "frn_previous_year_exists converted to float\n",
      "Dummified columns: \n",
      "['pricing_confidentiality_type', 'purpose', 'function', 'postal_cd', 'billed_entity_type', 'contract_type']\n",
      "(47165, 125)\n"
     ]
    }
   ],
   "source": [
    "print(\"*** STARTING PRE-PROCESSING FOR RAW DATA ***\")\n",
    "clean_data_predict = PreprocessRaw(raw_data_predict, verbose=True)\n",
    "clean_data_predict = clean_data_predict.applyall_predict()\n",
    "\n",
    "data_2019 = clean_data_predict.getdata()\n",
    "\n",
    "print data_2019.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "Querying data from DB connection\n",
      "Trying to establish initial connection to the server\n",
      "Success!\n",
      "Finished querying data\n",
      "RandomForestClassifier(bootstrap=False, class_weight='balanced',\n",
      "            criterion='gini', max_depth=30, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=5, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=350, n_jobs=-1, oob_score=False, random_state=7,\n",
      "            verbose=0, warm_start=False)\n",
      "(47165, 54)\n",
      "Querying data from DB connection\n",
      "Trying to establish initial connection to the server\n",
      "Success!\n",
      "Finished querying data\n",
      "y-variable distributions comparison:\n",
      "      index   purpose  prediction   absdiff\n",
      "0  internet  0.457153    0.563066  0.105912\n",
      "1       wan  0.354876    0.273868  0.081007\n",
      "2  upstream  0.131290    0.116930  0.014361\n",
      "3       isp  0.049102    0.037231  0.011871\n",
      "4  backbone  0.007579    0.008905  0.001326\n"
     ]
    }
   ],
   "source": [
    "### Individual Model Predictions\n",
    "\n",
    "## Purpose\n",
    "purpose_predictions = load_and_predict(data_2019, '1311') # your model_id from dl.ml_model_results_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purpose prediction columns: \n",
      "['line_item_id', 'prediction', 'backbone', 'internet', 'isp', 'upstream', 'wan']\n"
     ]
    }
   ],
   "source": [
    "print(\"purpose prediction columns: \")\n",
    "print(purpose_predictions.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add back frn_complete and original info\n",
    "ml_mass_update_qa_prf = pd.merge(raw_data_predict[['frn_adjusted','purpose', 'function']], purpose_predictions, left_on='frn_adjusted', right_on='line_item_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load Mappings, convert easy ones to dicts\n",
    "\n",
    "# connect_type_different = pd.read_csv('../data/connect_type_different.csv')\n",
    "# connect_type_different = connect_type_different.set_index('Connect Category ')\n",
    "# connect_type_different_dict = connect_type_different.to_dict()\n",
    "# connect_type_different_dict = connect_type_different_dict['Connect Type']\n",
    "\n",
    "# connect_type_same = pd.read_csv('../data/connect_type_same.csv')\n",
    "\n",
    "# function = pd.read_csv('../data/function.csv')\n",
    "# function = function.set_index('Connect Category ')\n",
    "# function_dict = function.to_dict()\n",
    "# function_dict = function_dict['Function']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Where model updated cc\n",
    "\n",
    "# model_1_cc_different = ml_mass_update_qa_final[ml_mass_update_qa_final.prediction_connect_category!=ml_mass_update_qa_final.connect_category]\n",
    "# model_1_cc_different['prediction_connect_type'] = model_1_cc_different['prediction_connect_category'].map(connect_type_different_dict)\n",
    "\n",
    "# ##remove predictions where we're changing a T-1 or fractional T-1 or ISDN BRI to be Fiber\n",
    "# model_1_cc_different = model_1_cc_different[~(((model_1_cc_different['connect_type']=='T-1')\n",
    "#                                                |(model_1_cc_different['connect_type']=='Fractional T-1')\n",
    "#                                                |(model_1_cc_different['connect_type']=='ISDN-BRI'))\n",
    "#                                               &((model_1_cc_different['prediction_connect_category']=='Lit Fiber')\n",
    "#                                                 |(model_1_cc_different['prediction_connect_category']=='Dark Fiber')))]\n",
    "\n",
    "# ##### Where model didn't update cc\n",
    "\n",
    "# model_1_cc_same = ml_mass_update_qa_final[ml_mass_update_qa_final.prediction_connect_category==ml_mass_update_qa_final.connect_category]\n",
    "# model_1_cc_same_cts = model_1_cc_same[['line_item_id','prediction_connect_category','connect_type']].merge(connect_type_same,left_on=['prediction_connect_category','connect_type'],right_on=['Connect Category ','Original Connect Type'],how='left')\n",
    "# model_1_cc_same_cts['prediction_connect_type'] = np.where(model_1_cc_same_cts['Update CT']==1,model_1_cc_same_cts['Connect Type'],model_1_cc_same_cts['connect_type'])\n",
    "\n",
    "# # filter for the 3 columns\n",
    "# model_1_cc_same = model_1_cc_same.merge(model_1_cc_same_cts[['line_item_id','prediction_connect_type']],on='line_item_id')\n",
    "# # union back\n",
    "# model_1_final = pd.concat([model_1_cc_different,model_1_cc_same]) \n",
    "\n",
    "# ##### Function update\n",
    "\n",
    "# model_1_final['prediction_function'] = model_1_final['prediction_connect_category'].map(function_dict)\n",
    "\n",
    "# # QA\n",
    "# print(model_1_final[['line_item_id','prediction_connect_category','prediction_connect_type']].groupby(['prediction_connect_category','prediction_connect_type']).count())\n",
    "# print(model_1_final[['line_item_id','prediction_connect_category','prediction_function']].groupby(['prediction_connect_category','prediction_function']).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### everywhere the model(s) predict purpose = ISP, _don’t update connect type or function_\n",
    "\n",
    "# model_1_final['prediction_connect_type'] = np.where(model_1_final['prediction_purpose']=='isp',None,model_1_final['prediction_connect_type'])\n",
    "# model_1_final['prediction_function'] = np.where(model_1_final['prediction_purpose']=='isp',None,model_1_final['prediction_function'])\n",
    "\n",
    "# model_1_final.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### csv for QA, eventual mass update in environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_mass_update_qa_prf.to_csv('../data/ml_mass_update_qa_prf.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47165, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_mass_update_qa_prf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
